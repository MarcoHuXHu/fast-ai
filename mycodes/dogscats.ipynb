{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import division,print_function\n",
    "\n",
    "import os, json\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import sys \n",
    "sys.path.append(os.path.abspath(\"..\\examples\"))\n",
    "\n",
    "import utils; reload(utils)\n",
    "from utils import plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pwd = str(os.getcwd()).split(\"\\\\\")\n",
    "pwd.pop()\n",
    "pwd.pop()\n",
    "spwd = \"/\".join(pwd)\n",
    "# path = spwd + \"/data/dogscats/\"\n",
    "path = spwd + \"/data/dogscats/sample/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# As large as you can, but no larger than 64 is recommended. \n",
    "# If you have an older or cheaper GPU, you'll run out of memory, so will have to decrease this.\n",
    "batch_size=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import our class, and instantiate\n",
    "import vgg16; reload(vgg16)\n",
    "from vgg16 import Vgg16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 微调(finetune)模型\n",
    "\n",
    "每次抓取一些图片用于训练(train)和验证(valid).  \n",
    "对于vgg, 样本必须分类放好, 比如:  \n",
    "data\\train\\cats\\*.jpg  \n",
    "data\\train\\dogs\\*.jpg  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16 images belonging to 2 classes.\n",
      "Found 8 images belonging to 2 classes.\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 12s - loss: 0.8440 - acc: 0.6875 - val_loss: 0.2865 - val_acc: 0.8750\n"
     ]
    }
   ],
   "source": [
    "vgg = Vgg16()\n",
    "\n",
    "batches = vgg.get_batches(path+'train', batch_size=batch_size)\n",
    "val_batches = vgg.get_batches(path+'valid', batch_size=batch_size*2)\n",
    "vgg.finetune(batches)\n",
    "vgg.fit(batches, val_batches, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 生成结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-34:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\anaconda2\\lib\\threading.py\", line 801, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\anaconda2\\lib\\threading.py\", line 754, in run\n",
      "    self.__target(*self.__args, **self.__kwargs)\n",
      "  File \"C:\\anaconda2\\lib\\site-packages\\keras\\engine\\training.py\", line 429, in data_generator_task\n",
      "    generator_output = next(self._generator)\n",
      "  File \"C:\\anaconda2\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 822, in next\n",
      "    index_array, current_index, current_batch_size = next(self.index_generator)\n",
      "  File \"C:\\anaconda2\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 645, in _flow_index\n",
      "    current_index = (self.batch_index * batch_size) % n\n",
      "ZeroDivisionError: integer division or modulo by zero\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batches, preds = vgg.test(path+'test/', batch_size = batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
