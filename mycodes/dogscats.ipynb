{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os, sys \n",
    "sys.path.append(os.path.abspath(\"..\\examples\"))\n",
    "\n",
    "from __future__ import division,print_function\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import utils; reload(utils)\n",
    "from utils import plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pwd = str(os.getcwd()).split(\"\\\\\")\n",
    "pwd.pop()\n",
    "pwd.pop()\n",
    "spwd = \"/\".join(pwd)\n",
    "path = spwd + \"/data/dogscats/\"\n",
    "path = spwd + \"/data/dogscats/sample/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# As large as you can, but no larger than 64 is recommended. \n",
    "# If you have an older or cheaper GPU, you'll run out of memory, so will have to decrease this.\n",
    "batch_size=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import our class, and instantiate\n",
    "import vgg16; reload(vgg16)\n",
    "from vgg16 import Vgg16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 微调(finetune)模型\n",
    "\n",
    "每次抓取一些图片用于训练(train)和验证(valid).  \n",
    "对于vgg, 样本必须分类放好, 比如:  \n",
    "data\\train\\cats\\*.jpg  \n",
    "data\\train\\dogs\\*.jpg  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16 images belonging to 2 classes.\n",
      "Found 8 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# 初始化模型并抓取图片\n",
    "vgg = Vgg16()\n",
    "batches = vgg.get_batches(path+'train', batch_size=batch_size)\n",
    "val_batches = vgg.get_batches(path+'valid', batch_size=batch_size*2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# finetune用于更新vgg16的各种类别(self.classes), 即加入线性层, 使得输出形态与batches的形态一致\n",
    "# fit则是训练这个线性层, 使得结果与数据一致\n",
    "# 没有这两步, vgg则会根据原有的1000个类别, 在下一步中进行预测\n",
    "vgg.finetune(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "3674/3674 [==============================] - 3293s - loss: 0.1534 - acc: 0.9584 - val_loss: 0.1410 - val_acc: 0.9705\n"
     ]
    }
   ],
   "source": [
    "vgg.fit(batches, val_batches, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 生成结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# 注意这里test目录下还要有一层目录, 再存放待识别的图片, 不然会找不到class\n",
    "# 以及vgg.test返回两个值, 一个是get_batches的结果, 另一个是predict的结果:\n",
    "# test_batches = self.get_batches(path, shuffle=False, batch_size=batch_size, class_mode=None)\n",
    "# return test_batches, self.model.predict_generator(test_batches, test_batches.nb_sample)\n",
    "\n",
    "batches, preds = vgg.test(path+'test/', batch_size = batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.0000e+00   3.7125e-07]\n",
      " [  9.9956e-01   4.4095e-04]\n",
      " [  1.0000e+00   3.2691e-13]\n",
      " [  1.0000e+00   3.8876e-09]\n",
      " [  8.5122e-08   1.0000e+00]\n",
      " [  7.5174e-15   1.0000e+00]\n",
      " [  1.0000e+00   1.3014e-12]\n",
      " [  1.0000e+00   1.8635e-07]]\n"
     ]
    }
   ],
   "source": [
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2L, 1000L)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = path + 'models/'\n",
    "if not os.path.exists(model_path): os.mkdir(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 储存和读取模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg.model.save_weights(model_path+'finetune1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg = Vgg16()\n",
    "vgg.model.load_weights(model_path+'finetune1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
