# 知识概念

## 深度学习三要素
**无限灵活的功能: Universal Approximation Theorem**  
**万能的参数拟合: 反向传播**  
**速度与设备可行: 高性能GPU**  



## 理论部分
-----

### 多层感知器Multi-Layer Perceptron(MLP)

前馈神经网络的一种, 包含至少三层神经节点(输入层, 输出层, 和至少一层隐藏层(hidden layer)). 除了输入节点外, 每个节点都使用非线性激活函数. MLP利用反向传播来训练. 注意与自然语言处理Natural Language Processing(NLP) 相区别.  
MLP是fully connected, 即其中任意节点, 都与下一层的每一个节点有连接, 权重为w<sub>ij</sub>.  

### 激活函数Activation function 
节点的激活函数确定了给定的输入或输入集下, 节点的输出. 如果激活函数都为线性, 则任意多层神经节点都可以优化成两层(input-output). 故而多层感知器一定是非线性激活函数, 比如sigmoid(S函数). 否则多层感知器会退化到单层模式.  
[各类激活函数优缺点比较](https://en.wikipedia.org/wiki/Activation_function)  

### 前馈神经网络Feedforward neural network
节点间连接无环的人工神经网络, 信息从输入层向输出层单相传播

### 通用近似理论[Universal Approximation Theorem](https://en.wikipedia.org/wiki/Universal_approximation_theorem) 
一个具有 有限的Neuron(神经元), 单层Hidden Layer 的 前馈(参数从输入层向输出层单向传播) 神经网络, 可以用来近似欧几里德空间有界闭合子集上的连续函数.  
换而言之, 前馈神经网络在拥有相应的参数时, 可以用来模拟各种各样的功能.

### Learning Techniques:  
神经网络利用训练集不断优化自身节点间权重, 最终收敛到误差足够小的状态.  此时神经网络习得目标函数.

### 过拟合Overfit:
对比于可获取的数据总量来说, 用过多参数, 使得模型只要足够复杂，就可以可以完美地适应训练集数据. 然而验证集上的正确率低于训练集, 说明模型不够一般化.


### 监督学习Supervised learning:
训练集有标签. 即用来训练的每一个例子, 都是输入数据和输出结果成对出现的. 

### 半监督学习与伪标签Semi-Supervised & Psudo-Labeling
半监督学习: 数据一部分带有标签, 一部分不带标签  
无监督学习: 数据完全没有标签  
比如statefarm中, 训练集(有标签)只有20000个, 而测试集(无标签)却有80000个. 测试集的数据虽然不能用于做监督学习的训练, 但是可以通过半监督学习帮助模型认识数据之间的结构.  
具体做法如下, 建立模型后先用训练集进行训练(包括验证集的验证), 然后利用这个模型(训练过的模型至少要能够提供相对好的正确率)对测试集进行预测, 预测的结果即为伪标签Psudo Label. 然后把测试集以及伪标签与训练集以及训练集的标签连接在一起, 再次对模型进行训练, 即为半监督学习.  
需要注意的是, 在混入伪标签的时候, 如果一个batch全是伪标签的数据, 则这个batch并不能代表数据的真正结构. 一般的标准是每个batch里面包含1/4到1/3的伪标签数据(训练集数据少可以反复使用).


### 反向传播Backpropagation & 梯度下降Gradient descent:
**反向传播**: 神经网络的一种学习方式. 将神经网络推算出的结果与正确结果比较, 利用预先设定的误差函数计算出误差值, 然后把误差反过来从输出层往输入层传播, 在此过程中调节权重.  

**梯度下降**: 非线性最优化中, 反向传播调节权重的一种方式. 通过计算误差对于权重变化的导数, 来改变权重使得误差减小. 故而反向传播只适用于激活函数可导情况.  
用梯度下降更新参数有两种方式:  
批梯度下降Batch Gradient Descent, 遍历全部数据集算一次损失函数, 然后算函数对各个参数的梯度, 更新梯度.  
随机梯度下降Stochastic Gradient Descent, 每看一个数据就算一下损失函数，然后求梯度更新参数.  

### Analytical Derivative(分析导数)
**在执行SGD的时候, loss的结果对于每个参数的导数如何去求?**
解析函数是局部上由收敛幂级数给出的函数, 所以一个可解析的loss, 由于是幂级数, 是无穷可导的, 且导数也是很好计算的.
虽然有一些非线性激活函数, 如relu, 在原点不可导, 不过计算机并不会考虑到“无穷”这样的数学上的概念, 所以relu的导数为0或1, 原点的导数取决于设置.


### Gradient - Momentum
不同于直接利用梯度对参数进行优化, momentum是先对之前所有的梯度取平均值, 然后在利用这个平均值对参数进行优化.  
单就梯度进行优化(最速下降), 搜索路径呈锯齿形, 损失函数很可能陷入到鞍点(saddle point), 即梯度在某些轴上变得很小, 但却未达到最优值.  比如:
```
m(i-1) = m(i-2) * 0.9 + g(i-1) * 0.1
m(i)    = m(i-1) * 0.9 + g(i) *0.1
```
其中0.9是可以设置的参数(参见RMSProp中到默认值rho=0.9)


### 学习率Learning Rate
Learning Rate决定了参数在梯度下降时随导数变化的大小. 一般SGD会使用一个常数作为lr, 然而这会有两个问题:

1. lr的大小导致的问题
如果lr太小, 则优化太慢, 可能无法在合理的时间内优化出模型; lr太大, 则改变虽然快, 但是会使得模型不稳定, 训练时有可能跳出最优区域, 并使得损失函数loss越来越大; 因此我们需要在训练过程中调整lr. 

2. 所有参数使用同一个lr的问题
而当参数的量级不同时(比如线性拟合中, 斜率=3, 轴距=300), 使用同一个lr就不合适了. 即使对输入数据进行正则化也没用. 这时就需要在每个方向上使用不同的lr, 即每个参数都有一个lr.

动态学习率即综合这两点, 在许多优化器中得到应有, 比如之后将介绍的Adagrad, RMSProp, Adam, Eve. 然而这些Optimizer仍然有一个需要输入的lr作为每个epoch的lr初始值, 这里的lr是一个数而非具体到每个方向上的向量, 一般选用0.1, 0.01, 0.001... 而如何设定这里的宏观lr, 方法则是通过一个小的数据集, 初始设定lr为一个很小的值, 然后逐步增大, 比较loss随lr的关系. 当lr增加到loss不在快速减少时停止. 


### 各类Optimizer
#### Adagrad
Adagrad基于参数方向之前的梯度来调整lr, 梯度大则lr小, 反之亦然. 具体为: 对之前的梯度值求平方和再开方(记作: lr2-norm), 下一个epoch的lr为当前lr除以lr2-norm.
```
lr(n+1) = lr(n) / (sqrt(sum(d(i) * d(i)))  / m)      当前为第n个epoch, d(i)代表第i步的梯度, m为每个epoch的步数, 1<=i<=m.
```
由于lr2-norm单调递增, 即lr(n+1)/lr(n)单调递减. 可以看出Adagrad是基于这样一个假设: 损失函数在某个参数方向上调整的路径越长, 在该方向越接近最优值, lr变化越小. 然而这样还是不能避免lr太大而逐渐跳出最优区域. 另一个问题就是维护所有参数每步的梯度则开销很大.

#### RMSProp
RMSProp是对Adagrad的改进, 在对梯度求平方和的时候会乘以一个权重(就像gradient momentum那样, 之前的平方和乘以0.9, 新的平方乘以0.1; 然而RMSProp并未在调整参数的时候使用梯度的平均值, 使用了的是Adam). 称为加权移动平均值. 这样越早期的梯度对更新lr的影响越小. 从而运行损失函数在最优点附近移动而不至于跳出去.  
更重要的是, RMSProp在一次epoch的每一步都会使用修改后的lr, 即每一步都会使用当前epoch设定的lr, 除以加权移动平均值, 这样lr的调整就会更加连续.  

#### Adam
Adam则是在RMSProp的基础上同时使用了gradient momentum, 即gradient的平均值来优化参数(momentum); 使用加权移动平均值来优化计算每一步优化参数时所使用的lr.    

#### Eve 
Eve是对于Adam的补充, 在每个epoch之后调整lr来自动完成Learning rate annealing. 既可能减小lr, 也可能增大lr. Eve会比较最终梯度的平方和的变化情况, 如果变化很小, 说明loss函数在这个epoch的路程很平坦, 可以增大lr; 如果变化剧烈, 则说明需要减小lr. 然而Eve可能的问题是: 当快接近最优区间时, Eve可能在一个epoch减小lr, 在下一个epoch又增加了lr.


### Learning Rate Annealing
像Adam, RMSProp这些是在每一个epoch设定初始lr, 每一步使用计算得到的lr来优化参数. . 训练模型的时候会先设置一个较大的lr, 在逐渐调小lr, 使得模型更加精确(Learning rate annealing).  
然而如果不断调小lr, 则会导致loss函数进入到一个狭窄的区域, 以至于在任意一个参数方向上轻微变化都会导致loss急剧变大. 这样的模型就不够general. 因此, 当lr调小到一定程度后, 又需要调大lr, 只有当loss达到最小且以较大的lr也跳不出去的时候, 这样模型才会比较general.

## 实践部分
-----

### 训练集train set 验证集validation set 测试集test set
一般需要将样本分成独立的三部分训练集(train set)，验证集(validation set)和测试集(test set)。其中训练集用来训练模型或确定模型参数，验证集用来确定网络结构或者控制模型复杂程度的参数，而测试集是为了测试已经训练好的模型性能如何。  
换而言之, 训练集和验证集都用于完善模型阶段, 当使用测试集时, 模型已经建立完全, 不应再有任何改动了

养成一个好的习惯: Train和Test的数据分开, Train完成前不去看Test的数据, 保持真实性

### 微调finetune
以课程中dogs&cats问题中vgg16为例, 默认情况下, 直接让vgg16对图像进行预测, 会得到按照vgg16默认的1000个分类进行预测并得到概率, 而要利用vgg16来解决dogs&cats, 则需要finetune, 使得vgg16能给出dog和cat两个分类的概率.

为了更好利用vgg16预测得到的信息(比如图片中有"骨头棒", 即按1000个分类骨头的概率较高, 那么结果更有可能是狗而不是猫), 可以在vgg16最后一层之后, 加入一层线性层. 输入为1000, 代表原来默认的1000个分类; 输出为2, 表示dog和cat. 然后将数据代入进行训练和验证.

**微调即删去原有模型的最后几层, 加入新层并重新训练**
对于猫和狗这样的问题而言, vgg16本身已经可以覆盖这个问题(可以识别不同种类的猫和狗), 而vgg16本身最后一层就是一个线性层, 用来生产1000个分类的概率, 所以vgg16的finetune就是pop最后一层, 然后加入新的线性层.

### One-Hot-Encoding
又称为一位有效编码, 方法是使用N位状态寄存器来对N个状态进行编码，每个状态都由他独立的寄存器位，并且在任意时候，其中只有一位有效。

比如一个类型有0, 1, 2三种状态, One-Hot-Encoding之后表示为001, 010, 101.


### Batch
梯度下降分为批梯度下降(BGD)和随机梯度下降(SGD), 前者计算量开销大, 计算速度慢, 不支持在线学习; 后者速度比较快, 但是收敛性能不太好, 可能在最优点附近晃来晃去, hit不到最优点, 也有可能两次参数的更新互相抵消掉，造成目标函数震荡的比较剧烈.

为了克服两种方法的缺点, 现在一般采用的是一种折中手段，mini-batch gradient decent, 小批的梯度下降, 这种方法把数据分为若干个批, 按批来更新参数, 这样, 一个批中的一组数据共同决定了本次梯度的方向, 下降起来就不容易跑偏, 减少了随机性, 另一方面因为批的样本数与整个数据集相比小了很多, 计算量也不是很大.