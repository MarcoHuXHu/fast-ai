# 第四课

## 优化器Optimizer

### Analytical Derivative(分析导数)
**在执行SGD的时候, loss的结果对于每个参数的导数如何去求?**
解析函数是局部上由收敛幂级数给出的函数, 所以一个可解析的loss, 由于是幂级数, 是无穷可导的, 且导数也是很好计算的.
虽然有一些非线性激活函数, 如relu, 在原点不可导, 不过计算机并不会考虑到“无穷”这样的数学上的概念, 所以relu的导数为0或1, 原点的导数取决于设置.


back propagation是逐层优化参数还是同时优化?
困在局部最优中, 应该在维度越高(参数越多)越难以出现吧



### Gradient - Momentum
不同于直接利用梯度对参数进行优化, momentum是先对之前所有的梯度取平均值, 然后在利用这个平均值对参数进行优化.  
单就梯度进行优化(最速下降), 搜索路径呈锯齿形, 损失函数很可能陷入到鞍点(saddle point), 即梯度在某些轴上变得很小, 但却未达到最优值.  比如:
```
m(i-1) = m(i-2) * 0.9 + g(i-1) * 0.1
m(i)    = m(i-1) * 0.9 + g(i) *0.1
```
其中0.9是可以设置的参数(参见RMSProp中到默认值rho=0.9)

### 学习率Learning Rate
Learning Rate决定了参数在梯度下降时随导数变化的大小. 一般SGD会使用一个常数作为lr, 然而这会有两个问题:

1. lr的大小导致的问题
如果lr太小, 则优化太慢, 可能无法在合理的时间内优化出模型; lr太大, 则改变虽然快, 但是会使得模型不稳定, 训练时有可能跳出最优区域, 并使得损失函数loss越来越大; 因此我们需要在训练过程中调整lr. 

2. 所有参数使用同一个lr的问题
而当参数的量级不同时(比如线性拟合中, 斜率=3, 轴距=300), 使用同一个lr就不合适了. 即使对输入数据进行正则化也没用. 这时就需要在每个方向上使用不同的lr, 即每个参数都有一个lr.

动态学习率即综合这两点, 在许多优化器中得到应有, 比如:

### 各类Optimizer
#### Adagrad
Adagrad基于参数方向之前的梯度来调整lr, 梯度大则lr小, 反之亦然. 具体为: 对之前的梯度值求平方和再开方(记作: lr2-norm), 下一个epoch的lr为当前lr除以lr2-norm.
```
lr(n+1) = lr(n) / (sqrt(sum(d(i) * d(i)))  / m)      当前为第n个epoch, d(i)代表第i步的梯度, m为每个epoch的步数, 1<=i<=m.
```
由于lr2-norm单调递增, 即lr(n+1)/lr(n)单调递减. 可以看出Adagrad是基于这样一个假设: 损失函数在某个参数方向上调整的路径越长, 在该方向越接近最优值, lr变化越小. 然而这样还是不能避免lr太大而逐渐跳出最优区域. 另一个问题就是维护所有参数每步的梯度则开销很大.

#### RMSProp
RMSProp是对Adagrad的改进, 在对梯度求平方和的时候会乘以一个权重(就像gradient momentum那样, 之前的平方和乘以0.9, 新的平方乘以0.1; 然而RMSProp并未在调整参数的时候使用梯度的平均值, 使用了的是Adam). 称为加权移动平均值. 这样越早期的梯度对更新lr的影响越小. 从而运行损失函数在最优点附近移动而不至于跳出去.  
更重要的是, RMSProp在一次epoch的每一步都会使用修改后的lr, 即每一步都会使用当前epoch设定的lr, 除以加权移动平均值, 这样lr的调整就会更加连续.  

#### Adam
Adam则是在RMSProp的基础上同时使用了gradient momentum, 即gradient的平均值来优化参数(momentum); 使用加权移动平均值来优化计算每一步优化参数时所使用的lr.    
像Adam, RMSProp这些是在每一个epoch设定初始lr, 每一步使用计算得到的lr来优化参数. . 训练模型的时候会先设置一个较大的lr, 在逐渐调小lr, 使得模型更加精确(Learning rate annealing). 

#### Eve 
Eve是对于Adam的补充, 在每个epoch之后调整lr来自动完成Learning rate annealing. 既可能减小lr, 也可能增大lr. Eve会比较最终梯度的平方和的变化情况, 如果变化很小, 说明loss函数在这个epoch的路程很平坦, 可以增大lr; 如果变化剧烈, 则说明需要减小lr. 然而Eve可能的问题是: 当快接近最优区间时, Eve可能在一个epoch减小lr, 在下一个epoch又增加了lr.


## 实践部分

### 利用sample来设定参数
一些人为设定的参数, 比如lr, dropout, 是与模型相关的, 而非随着训练而改变. 因此可以先选一个sample, 来找出这些参数比较合理的值.  
比如对于lr: 如果lr跟随机选择的正确率差不多(比如mnist有10个class, accuracy约为0.1), 这就说明lr可能太大了. 当lr设定到正确率明显高于随机, 则可以考虑调大lr. PS: 第三课中Adam设置lr=0.1会导致怎么训练都是随机结果就是lr太大导致无法优化.


### 简单的Batch Normalization
相对于上一课mnist中手动对输入数据进行normalization, 可以在模型的第一层就放置batch-normalization, 这样就可以起到作用了.



### Pre-Trained Model
使用预先训练过的模型. 由于CNN里面, 卷积层在训练的时候消耗的时间最多. 而卷积层的作用是识别图中的特征, 像ImageNet, Vgg16这些模型的卷积层已经被利用大量数据训练得足够好. 所以很多问题完全可以使用这些模型的卷积层, 而重点对之后的Dense 层训练.  
使用时把比如Vgg16的卷积层包括进来, 然后predict出数据的feature, 得到一个numpy array. 这样还可以保存到本地, 下次使用直接载入.  
注意使用Pre-Trained的模型就不可以使用data-argumentation了. 因为data-argumentation每次会随机给输入的图片加入旋转等参数, 得到feature之后, 训练Dense层的data-argumentation对于图片的改变是不同的. 正确的data-argumentation做法是对数据集进行改变, 利用旋转缩放等方法把训练数据扩大.  
而如果想要验证这个问题的关键是在Dense层而非Conv层, 可以在运行几个epoch后, 把Conv层设置为trainable, 然后看看会不会对于精度有影响. 如果无影响则说明判断正确, 可以只用关心Dense层.  



## 半监督学习与伪标签Semi-Supervised & Psudo-Labeling
半监督学习: 数据一部分带有标签, 一部分不带标签  
无监督学习: 数据完全没有标签  
比如statefarm中, 训练集(有标签)只有20000个, 而测试集(无标签)却有80000个. 测试集的数据虽然不能用于做监督学习的训练, 但是可以通过半监督学习帮助模型认识数据之间的结构.  
具体做法如下, 建立模型后先用训练集进行训练(包括验证集的验证), 然后利用这个模型(训练过的模型至少要能够提供相对好的正确率)对测试集进行预测, 预测的结果即为伪标签Psudo Label. 然后把测试集以及伪标签与训练集以及训练集的标签连接在一起, 再次对模型进行训练, 即为半监督学习.  
需要注意的是, 在混入伪标签的时候, 如果一个batch全是伪标签的数据, 则这个batch并不能代表数据的真正结构. 一般的标准是每个batch里面包含1/4到1/3的伪标签数据(训练集数据少可以反复使用).



## 协同过滤Collaborative Filtering
此刻我们从CNN进入到Natural Language Processing (NLP)的学习, 从协同过滤以及其在推荐系统的应用开始讲起

### 推荐系统
推荐系统是用来预判一个人会喜欢什么, 有多么喜欢. 一般有两种方式: 第一种是利用比如用户调查这样的信息(称之为元数据meta-data)来过滤出推荐结果. 比如微博选择感兴趣的标签, 然后就会收到相关推送. 另一种就是协同过滤.  
协同过滤则是通过找到与你喜好相似的用户, 然后根据这些用户的喜好来得到推荐结果. 而“喜好相似”, 以电影推荐的例子来说, 则是对相同电影打分接近.  
在数据集足够大的情况下, 协同过滤的效果会比元数据过滤要好得多. 而且对于协同过滤的结果再施加元数据过滤并不会对准确率有什么提高(因为要想知道一个人的爱好, 直接询问, 还不如观察这个人的行为来得可靠).  
