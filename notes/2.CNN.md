# 卷积神经网络 Convolutional Neural Network (part 1)

### 卷积运算 Correlation & Convolution

Correlation:
$$
F \circ I(x) = \sum_{i=1}^{n}F(i)I(x+i)
$$
Convolution:
$$
F \circ I(x) = \sum_{i=1}^{n}F(i)I(x-i)
$$
Convolution就是将filter先转置在做Correlation

以一个3*3的filter为例, 现有一个矩阵A, 其中一部分为:  
$
\left[
  \begin{matrix}
... & A_{i-1,j-1}    &  A_{i-1,j}  &   A_{i-1,j+1} & ...  \\
... & A_{ i,j-1}      & A_{ i,j}     &   A_{ i,j+1} &   ...  \\
... & A_{ i+1,j-1} & A_{ i+1,j} &   A_{ i+1,j+1} & ...
  \end{matrix}
\right]
$

filter矩阵X为:

$
\left[
  \begin{matrix}
   1 & 2 & 3 \\
   4 & 5 & 6 \\
   7 & 8 & 9
  \end{matrix}
\right]
$

则Correlation为:
$
X^{'}_{i,j} = 
1 * A_{i-1,j-1} + 2 * A_{i-1,j} + 3 * A_{i-1,j+1} + 
4 * A_{ i,j-1} + 5 * A_{ i,j} + 6 * A_{ i,j+1} + 
7 * A_{ i+1,j-1} + 8 * A_{ i+1,j} + 9 * A_{ i+1,j+1}
$
Convolution为:
$
X^{'}_{i,j} = 
9 * A_{i-1,j-1} + 8 * A_{i-1,j} + 7 * A_{i-1,j+1} + 
6 * A_{ i,j-1} + 5 * A_{ i,j} + 4 * A_{ i,j+1} + 
3 * A_{ i+1,j-1} + 2 * A_{ i+1,j} + 1 * A_{ i+1,j+1}
$


## Keras中的相关层
这里给出Keras文档中CNN相关的层的作用和部分参数说明

### 常用层
-----
### Dense全联通层
```
keras.layers.core.Dense(units, activation=None, use_bias=True)
```
(省略了初始化, 正则项, 约束项)
比如:
```
model.add(Dense(32, input_shape=(16,)))
```
Dense就是常用的全连接层, 所实现的运算是:  
output = activation(dot(input, kernel)+bias). 即对输入的张量与权重矩阵kernel做点乘, 然后与bias张量相加, 最后在经过非线性激活函数activation.  

其中activation是逐元素计算的激活函数，kernel是本层的权值矩阵，bias为偏置向量，只有当use_bias=True才会添加.

Dense层的参数个数为input(上一层output)节点数 * output节点数



### Dropout
```keras.layers.core.Dropout(rate)```
Dropout将在训练过程中每次更新参数时按一定概率（rate）随机断开输入神经元(Activation=0), 防止过拟合

值得注意到是, 当我们设置了Dropout, 比如rate=0.25(25%), 则训练中每次会有25%的机会被断开, 而测试的时候却不会Dropout, 这样平均下来, 训练中计算出来的权重只有测试时的75%. 因此需要对权重进行处理(好在Keras会在加入Dropout时自动处理的, 不需要手动rescaling了).



### MaxPooling池化层:
**池化Pooling**: 把卷积特征划分成为m\*n个x\*y大小的不相交区域, 计算区域上特征的最大值(MaxPooling), 或者平均值, 作为Pooling后的卷积特征. Pooling后的卷积特征矩阵变成m*n的形状.  

比如在vgg16中, 利用```model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))```来进行Pooling, 这样下一层的特征矩阵就会在x, y方向都变为原来的一半. (strides: 步长值, 若小于pool_size则Pooling区域会相交).  

为了不让信息在Pooling的过程中损失太多, 通常会在Pooling后加入更多的filter. 如vgg中的filter数量在Pooling之后翻倍(64, 128, 256).



### Convolution卷积层
与Dense层不同, Convolution层进行的不是矩阵点乘, 而是特征矩阵与filter做卷积.

首先, 利用ZeroPadding给图像边界填充0, 方便卷积.  
然后, 把filter对图像做卷积, 突出特征(比如MNIST例子中, Top filter会突出顶边).  

注意, 如果第一层有x个filter, 则下一层每一个filter都是一个张量, 每个filter有x个filter. 即如果filter的大小是3*3, 则之后的filter都会是3\*3\*前一层filter个数的张量, 该层的output为上一层所有filter的output与这一层对应filter做卷积, 再相加的和.
比如mnist中第一二层卷积层, 各加入了32个filter, 所以第一层的参数个数为: `3 * 3 * 32 + 32 = 320`, 第二次参数的个数为: ` 3 * 3 * 32 * 32 + 32 = 9248`. 加的这个32, 与`Dense层参数 = input * output + x`中的x的意义有疑问, 也许是Batch Normalization引入的?

接着, 对突出了特征的矩阵做Pooling, 一来可以选择区域中最有特点的部分(MaxPooling), 二来可以减小特征矩阵. 从而减少运算量, 并防止过拟合.  
最后, 利用反向传播和梯度下降, 来优化filter.  

训练时, 全联通层通过反向传播调整矩阵中的数值, 于是优化了参数, 而卷积层则是通过反向传播调整filter. 所以初始模型的时候随机选择filter, 然后让模型在训练中自动得到最好的filter(匹配图像与标签正确率高).



### ZeroPadding2D:
对2D输入（如图片）的边界填充0，以控制卷积以后特征图的大小


### Softmax
$$
P(x_{j}) = \frac{e^{x_{j}}}{\sum_{i=1}^{n}e^{x_i}}
$$
Activation的一种, 用于最后一层, 对Output进行修饰, 使得所有概率和为1, 且概率最高的接近1, 其余概率较小的接近0, 以接近于One-Hot编码的标签. 而且对于Output为负数的情况, 比使用绝对值更加合理.


### Data Augmentation
当数据不足时, 通过对训练数据的图片进行平移, 旋转, 翻转等操作(shuffle=True)产生更多训练集数据, 而验证数据不应该被改变


### Batch Normalization
Normalization(正则化?标准化), 是把给定数据的每个元素, 减去数据集的平均值, 再除以数据集的标准差. 这样可以使得所有的数据都被缩放到相同的尺度(以"从均值到标准差的距离"为单位). (通常对于图像输入的预处理, 只需要减去平均值而不需要除以标准差.)

这样做的原因是, 一个相较于其他输入数据而言特别大的输入值可能会导致神经网络变得非常不稳定, 这种不平衡的数据可能会叠加到各个层, 使得梯度也非常不平衡, 从而难以优化(比如出现指数爆炸).

然而一般的正则化后还是会有可能出现不平衡的值. 如果只是对激活函数的结果进行正则化, 则仍然无法完全防止SGD产生新的不平衡的值, 而且SGD也会倾向于去抵消这个正则化的优化. 而批正则化在此基础上加入了两个补充:
1. 在对激活函数结果正则化之后, 对结果乘以一个任意设定的参数, 在加上另一个参数, 这样可以设置一个新的标准差和平均值.
2. 把原先正则化的标准差和平均值, 以及新加入到这两个参数都设置成可训练模式(Trainable)
因为正则化被引入到了梯度计算中了, 所以在更新参数的时候也会带有正则化的优化, 这样可以保证权重值不会被训练到过高或过低, 并且保证了如果某一层的确需要调整标准差和平均值的时候可以自动完成.

任何一个神经网络都应该要加入批正则化处理, 能大大加快训练速度(防止不平衡值导致不稳定而难以训练), 而且因为降低了无关的不平衡值的影响, 批正则化处理也有助于降低过拟合.



### 更深层次微调

vgg是根据ImageNet的数据来训练模型的, 具有足够的能力来分辨猫和狗(事实上可以分辨猫和狗的种类), 因此只需要修改最后一层的全联通层, 使生成的结果适应问题要求即可. 而对于Statefarm(辨别分心驾驶), 就可能不太管用(难以识别图片中人物的动作含义). 所以要重新训练更多的全联通层. 因为filter仍然可以用于此问题, 因此不需要重新训练卷积层. 但对于医学图像(更高分辨/单色/识别模式不同于一般物体), 则需要重新训练卷积层.

所以如果不需要修改卷积层, 可以先计算卷积后的结果然后保存下来(利用bcolz), 以此为输入, 再加入新的层进行训练, 可以大大节约时间(毕竟卷积计算和反向传播的速度远远慢于全联通层)

### 做mnist的一点体会

mnist是keras里面就有的一个数据集, 直接导入就可以下载并以numpy_array储存. 目的是识别手写数字(28*28像素, 单色)
1. 要记得在输入的数据中加入一个维度, 这是因为卷积层会把HGB通道作为一个维度, 而mnist是单色的, 所以要加入这一个维度, 且大小为1. (RGB则为3)  
2. Batch Normalization中等axis, 默认状态下为-1, 对于图像识别, 要设置为表示色彩通道的axis.  

**然而现在发现xjb设置axis也不会有太多影响, 反而只要一修改Adam的lr就会出问题**(这其实就是lr设置太大直接跳出最优区域)

### 利用sample来设定参数
一些人为设定的参数, 比如lr, dropout, 是与模型相关的, 而非随着训练而改变. 因此可以先选一个sample, 来找出这些参数比较合理的值.  
比如对于lr: 如果lr跟随机选择的正确率差不多(比如mnist有10个class, accuracy约为0.1), 这就说明lr可能太大了. 当lr设定到正确率明显高于随机, 则可以考虑调大lr. PS: 第三课中Adam设置lr=0.1会导致怎么训练都是随机结果就是lr太大导致无法优化.  
在新版的fastai中`lr_find()`就是使用小部分sample来找到比较好的lr, 具体参考1.background中学习率的部分


### 简单的Batch Normalization
相对于上一课mnist中手动对输入数据进行normalization, 可以在模型的第一层就放置batch-normalization, 这样就可以起到作用了.


### Pre-Trained Model
使用预先训练过的模型. 由于CNN里面, 卷积层在训练的时候消耗的时间最多. 而卷积层的作用是识别图中的特征, 像ImageNet, Vgg16这些模型的卷积层已经被利用大量数据训练得足够好. 所以很多问题完全可以使用这些模型的卷积层, 而重点对之后的Dense 层训练.  
使用时把比如Vgg16的卷积层包括进来, 然后predict出数据的feature, 得到一个numpy array. 这样还可以保存到本地, 下次使用直接载入.  
注意使用Pre-Trained的模型就不可以使用data-argumentation了. 因为data-argumentation每次会随机给输入的图片加入旋转等参数, 得到feature之后, 训练Dense层的data-argumentation对于图片的改变是不同的. 正确的data-argumentation做法是对数据集进行改变, 利用旋转缩放等方法把训练数据扩大.  
而如果想要验证这个问题的关键是在Dense层而非Conv层, 可以在运行几个epoch后, 把Conv层设置为trainable, 然后看看会不会对于精度有影响. 如果无影响则说明判断正确, 可以只用关心Dense层.  


### Learning Rate Annealing
像Adam, RMSProp这些是在每一个epoch设定初始lr, 每一步使用计算得到的lr来优化参数. . 训练模型的时候会先设置一个较大的lr, 在逐渐调小lr, 使得模型更加精确(Learning rate annealing).  

然而如果不断调小lr, 则会导致loss函数进入到一个狭窄的区域, 以至于在任意一个参数方向上轻微变化都会导致loss急剧变大. 这样的模型就不够general. 因此, 当lr调小到一定程度后, 又需要调大lr, 只有当loss达到最小且以较大的lr也跳不出去的时候, 这样模型才会比较general.  
在fastai中只要在`fit()`中设定`cycle_len`参数, lr就会按照类似于`cos()+1`的方式随着mini-batch变化,  `cycle_len=1`表示1个epoch后lr回到初始值.  

(在新版的fastai中)对于非Pre-train的模型, 即卷积层也需要训练的模型, 可以使用一组不同的lr. 越顶层(比如最开始识别对角线的)的lr越小, 比如从上到下[0.001, 0.01, 0.1]. 这是因为越往上的卷积层, 特征越general, 训练时的变化越小; 越往下越customize, 训练时的变化越大, 所需要的lr也要相应变大.



## 训练图像识别模型的一般步骤(预训练模型来自fastai)
1. 使用Data-Augmentation, 设置`precompute=True`.  
2. 使用`lr_find()`来找到合适的lr, 即根据lr与loss的图像, 找到loss下降比较快的lr或者loss不动的lr/10.  
3. 对模型的最后一层训练1-2个epoch, 这里是第一次finetune.  
4. 对模型的最后一层使用Data-Augmentation训练2-3个epoch(这里设置`precompute=False`), 同时设置`cycle_len=1`(表示每个epoch结束lr回到设定值).  
5. (以及课件中的6-7步), 设定参数, 将所有layer进行unfreeze, 把最早的几层对lr设置成底层lr的百分之一到千分之一, 再次使用`lr_find()`.  
6. 设置`cycle_mult=2`, 训练直到过拟合.  



# 卷积神经网络 Convolutional Neural Network (part 2)

## Resnet(Residual Network残差网络)
对于一般的图像识别的finetune而言, 卷积层一般是不动的, 可以直接使用输入数据经过卷积层的结果来训练. 所谓残差, 即上一次Hidden层的输出与这一次Hidden层的输出之差. Resnet训练优化的就是这个残差函数. Resnet有很多个Block, 每一个Block内有由若干个卷积层. 该Block的输出为: 输入Hidden层经过这些卷积层运算的结果与输入Hidden层之和.  
设每个卷积层的运算为C, Block进入时的Hidden为H_t, Resnet的这个Block的输出H_(t+1)为:  
H_(t+1) = H_t + C(C(C(...(H_t)...)))  
残差R(H_t)为:  
R(H_t) = H_(t+1) - H_t
可以看出, Resnet输出的是两个Block之间的差, 这样通过不断优化两个Block之间的残差, 使得前一个Block不断接近答案. 另外, 每个Block的首尾需要作求和运算, 则其输出的维度必须一致, 则MaxPooling只能放在Block之间.


## Data Leakage
有时候一些来自于输入, 但是又和实际应用无关的数据, 会大大提高模型的准确率. 比如在Fisheries中, 照片的长宽会与输出有很明显的关联. 照片的长款可以反映拍照的相机的类型, 从而与某一艘船对应起来, 而船只会在固定海域航行, 拍摄到的鱼的种类也与此相关, 因此模型通过学习照片的长宽就能很好的预测鱼的种类了. 然而这样建立出来的模型对于实际应用则没有太大帮助, 只要船上的相机与训练集不同, 就会导致很大偏差.

### Multi-Input: 加入Metadata
比如在Fiesheries中, 利用函数式模型, 加入图片大小作为metadata:  
```
# 预训练模型经过卷积层后的结果
inp = Input(conv_layers[-1].output_shape[1:])

# 图像的size经过batchnormalization
sz_inp = Input((len(id2size),))
bn_inp = BatchNormalization()(sz_inp)

x = MaxPooling2D()(inp)
x = BatchNormalization(axis=1)(x)
x = Dropout(p/4)(x)
x = Flatten()(x)
x = Dense(512, activation='relu')(x)
x = BatchNormalization()(x)
x = Dropout(p)(x)
x = Dense(512, activation='relu')(x)
x = BatchNormalization()(x)
x = Dropout(p/2)(x)

# 将metadata合并入模型
x = merge([x,bn_inp], 'concat')
x = Dense(8, activation='softmax')(x)
```

## Redundant Metadata
事实上, 我们并不需要指定让模型学习Data Leakage的metadata, 模型也会自动学习这些特征. 因此我们就算给模型提供这些Metadata去学习, 也不会提高正确率. 这就是Redundant Metadata. 比如在之前的IMDB问题中, 即使给模型指定一些用户/电影的metadata去学习, 也不会提高正确率了.


## Multi Output: 给目标加边框
在Fiesheries中有人手动给照片中的鱼加入了边框, 利用这些数据, 可以训练模型在识别鱼的种类的同时, 训练如何加入包含鱼的边框. 这就需要模型有两个不同的输出, 一个是鱼的种类, 另一个是边框的坐标和长宽.  
建立模型跟之前没什么区别, 只是加入了一层`x_bb = Dense(4, name='bb')(x)`用于将前面层的结果与边框坐标(x, y), 长宽(height, width)关联的全联通层.  
```
inp = Input(conv_layers[-1].output_shape[1:])
x = MaxPooling2D()(inp)
x = BatchNormalization(axis=1)(x)
x = Dropout(p/4)(x)
x = Flatten()(x)
x = Dense(512, activation='relu')(x)
x = BatchNormalization()(x)
x = Dropout(p)(x)
x = Dense(512, activation='relu')(x)
x = BatchNormalization()(x)
x = Dropout(p/2)(x)
x_bb = Dense(4, name='bb')(x)
x_class = Dense(8, activation='softmax', name='class')(x)
```
编译和训练:  
```
model = Model([inp], [x_bb, x_class])
model.compile(Adam(lr=0.001), loss=['mse', 'categorical_crossentropy'], metrics=['accuracy'],
             loss_weights=[.001, 1.])
model.fit(conv_feat, [trn_bbox, trn_labels], batch_size=batch_size, nb_epoch=3, 
             validation_data=(conv_val_feat, [val_bbox, val_labels]))            
```
这样的模型可以提高正确率.

